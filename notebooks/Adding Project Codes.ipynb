{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Project Codes csv\n",
    "Download the Project Codes spreadsheet on google as a `.csv` file and save it to the parent directory of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Code</th>\n",
       "      <th>Formal Name</th>\n",
       "      <th>Still Active\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANO</td>\n",
       "      <td>Kiam Marcelo Junio</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP</td>\n",
       "      <td>The Algebra Project</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS</td>\n",
       "      <td>Afternoon Snatch</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV</td>\n",
       "      <td>Ambivert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BF</td>\n",
       "      <td>Brave Futures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project Code          Formal Name Still Active\\n\n",
       "0          ANO   Kiam Marcelo Junio            NaN\n",
       "1           AP  The Algebra Project            NaN\n",
       "2           AS     Afternoon Snatch            NaN\n",
       "3           AV             Ambivert            NaN\n",
       "4           BF        Brave Futures            NaN"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_codes_df = pd.read_csv('../project_codes.csv')\n",
    "proj_codes_df = proj_codes_df.drop(columns=['name'])\n",
    "proj_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_codes_df.index=proj_codes_df['Project Code'] # sets the index as the project code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data we'll use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df['project_id'] = df['Project ID'].fillna(df['Project Code'])\n",
    "    df['project_id'] = df['project_id'].fillna(df['Unnamed: 0'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_datetimes(file_name):\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    re_string = r'\\((.*?)\\)' # regex string for finding window start and end dates\n",
    "\n",
    "    match = re.findall(re_string, file_name)\n",
    "    start = match[0].split(\"_\")\n",
    "    start_month = int(start[0])\n",
    "    start_day = int(start[1])\n",
    "    start_year = int(start[2])\n",
    "    start_dt = datetime(month=start_month, day=start_day, year=start_year)\n",
    "    \n",
    "    end = match[1].split(\"_\")\n",
    "    end_month = int(end[0])\n",
    "    end_day = int(end[1])\n",
    "    end_year = int(end[2])\n",
    "    end_dt = datetime(month=end_month, day=end_day, year=end_year)\n",
    "    return start_dt, end_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define locations of the files we want to use\n",
    "data_dir = '../data/Spreadsheets_2019/'\n",
    "time_window_dirs = os.listdir(data_dir) # << a list of the file names in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "vimeo_device_dfs = []\n",
    "vimeo_region_dfs = []\n",
    "vimeo_video_dfs = []\n",
    "vimeo_date_dfs = []\n",
    "vimeo_source_dfs = []\n",
    "\n",
    "for window_dir in time_window_dirs:\n",
    "    file_names = os.listdir(data_dir+window_dir)\n",
    "    for file_name in file_names:\n",
    "        start_dt, end_dt = get_window_datetimes(file_name)\n",
    "        if 'Vimeo_Device' in file_name:\n",
    "            vimeo_device_df = pd.read_csv(data_dir+window_dir+\"/\"+file_name)\n",
    "            vimeo_device_df['start'] = start_dt\n",
    "            vimeo_device_df['end'] = end_dt\n",
    "            vimeo_device_dfs.append(vimeo_device_df)\n",
    "        if 'Vimeo_Region' in file_name:\n",
    "            vimeo_region_df = pd.read_csv(data_dir+window_dir+\"/\"+file_name)\n",
    "            vimeo_region_df['start'] = start_dt\n",
    "            vimeo_region_df['end'] = end_dt\n",
    "            vimeo_region_dfs.append(vimeo_region_df)\n",
    "        if 'Vimeo_Video' in file_name:\n",
    "            video_df = pd.read_csv(data_dir+window_dir+\"/\"+file_name)\n",
    "            video_df.columns = ['Project ID'] + video_df.columns[1:].to_list() # make the project id column name consistent\n",
    "            video_df.plays = video_df.plays.replace('\\r\\n', np.nan)\n",
    "            video_df = video_df[~video_df.isnull().all(axis=1)] # remove all completely null rows\n",
    "            video_df['start'] = start_dt\n",
    "            video_df['end'] = end_dt\n",
    "            vimeo_video_dfs.append(video_df)\n",
    "        if 'Vimeo_Date' in file_name:\n",
    "            vimeo_date_df=pd.read_csv(data_dir+window_dir+\"/\"+file_name)\n",
    "            vimeo_date_df['start'] = start_dt\n",
    "            vimeo_date_df['end'] = end_dt\n",
    "            vimeo_date_dfs.append(vimeo_date_df)\n",
    "        if 'Vimeo_Source' in file_name:\n",
    "            vimeo_source_df = pd.read_csv(data_dir+window_dir+\"/\"+file_name)\n",
    "            vimeo_source_df['start'] = start_dt\n",
    "            vimeo_source_df['end'] = end_dt\n",
    "            vimeo_source_dfs.append(pd.read_csv(data_dir+window_dir+\"/\"+file_name))\n",
    "            \n",
    "vimeo_device_df = pd.concat(vimeo_device_dfs, axis=0, sort=False)\n",
    "vimeo_region_df = pd.concat(vimeo_region_dfs, axis=0, sort=False)\n",
    "vimeo_video_df = pd.concat(vimeo_video_dfs, axis=0, sort=False)\n",
    "vimeo_date_df = pd.concat(vimeo_date_dfs, axis=0, sort=False)\n",
    "vimeo_source_df = pd.concat(vimeo_source_dfs, axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conver `Project ID` \"2QIK\" to \"TQIK\" for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "vimeo_video_df['Project ID'] = vimeo_video_df['Project ID'].replace(to_replace={'2QIK':'TQIK'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Code Estimator\n",
    "So far this seems to be working best even though it is the most simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_proj_code(video_name):\n",
    "    potential_codes = []\n",
    "    for ind, row in proj_codes_df.iterrows():\n",
    "        code, proj = row['Project Code'], row['Formal Name']\n",
    "        if proj.lower() in video_name.lower():\n",
    "            potential_codes.append(code)\n",
    "    return potential_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_codes = vimeo_video_df['name'].apply(estimate_proj_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated 455 codes out of 3019\n"
     ]
    }
   ],
   "source": [
    "x = len(estimated_codes) - np.sum(len([1 for i in estimated_codes if len(i) > 0]))\n",
    "print(\"Estimated %s codes out of %s\" % (x, len(vimeo_video_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to have a consistent way of double checking these against the project codes in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Spacy PhraseMatcher](https://spacy.io/api/phrasematcher)\n",
    "[Install Spacy](https://spacy.io/usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import PhraseMatcher\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_doc(name):\n",
    "    return nlp(name.lower().translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed449562e6343a2a25432cbcfa85b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=86.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kiam marcelo junio]\n",
      "[the algebra project]\n",
      "[afternoon snatch]\n",
      "[ambivert]\n",
      "[brave futures]\n",
      "[brujos]\n",
      "[bronx cunt tour]\n",
      "[brown girls]\n",
      "[black melodies]\n",
      "[brand new boy]\n",
      "[borderd]\n",
      "[bsayf by roy kinsey]\n",
      "[been there]\n",
      "[code]\n",
      "[the conspiracy theorist]\n",
      "[damaged goods]\n",
      "[darling shear]\n",
      "[for better]\n",
      "[filipino fusions]\n",
      "[fame]\n",
      "[full out]\n",
      "[fobia]\n",
      "[freaky phyllis]\n",
      "[the furies]\n",
      "[fck stan]\n",
      "[futurewomen]\n",
      "[fck yes]\n",
      "[granny ballers\n",
      "]\n",
      "[the haven]\n",
      "[the hoodoisie]\n",
      "[hookups]\n",
      "[i  love me]\n",
      "[damaged goods]\n",
      "[good enough]\n",
      "[open tv]\n",
      "[geetas guide to moving on]\n",
      "[the hoodosie]\n",
      "[hair story]\n",
      "[hook ups]\n",
      "[it goes unsaid]\n",
      "[inertia]\n",
      "[in real life]\n",
      "[just call me ripley]\n",
      "[kickin it]\n",
      "[kings and queens]\n",
      "[kissing walls\n",
      "]\n",
      "[lipstick city]\n",
      "[let go and let god]\n",
      "[low strung]\n",
      "[michaela angela davis]\n",
      "[movement matters]\n",
      "[melody set me free]\n",
      "[night night]\n",
      "[nupita obama creates vogua]\n",
      "[outtakes]\n",
      "[on the verge]\n",
      "[prep4love ,  p4l ,  dr every woman ,  one little pill\n",
      "]\n",
      "[project basho]\n",
      "[pay day]\n",
      "[public relations]\n",
      "[philadelphia voices of pride]\n",
      "[quare life]\n",
      "[queer the air]\n",
      "[the roach is coming]\n",
      "[renee]\n",
      "[reality is not good enough]\n",
      "[starving artists]\n",
      "[seeds]\n",
      "[searching for isabelle]\n",
      "[stargayzer\n",
      "]\n",
      "[shift]\n",
      "[sur la nuit with alexa grae]\n",
      "[southern for pussy]\n",
      "[symbiotic]\n",
      "[the exquisite corpse]\n",
      "[the north pole]\n",
      "[two queens in a kitchen]\n",
      "[triggers]\n",
      "[the right swipe]\n",
      "[the t]\n",
      "[uneverything]\n",
      "[united states of aliens]\n",
      "[velvet]\n",
      "[yogma]\n",
      "[you should know this by now]\n",
      "[youre so talented]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code, row in tqdm(proj_codes_df.iterrows(), total=len(proj_codes_df)):\n",
    "    names = [name_to_doc(n) for n in row['Formal Name'].split('|')]\n",
    "    print(names)\n",
    "    phrase_matcher.add(code, None, *names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d676a7cd4d4cba9689b3d1a6eded61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3019.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert all the video titles to spacy objects\n",
    "video_titles = []\n",
    "\n",
    "for name in tqdm(vimeo_video_df['name'], total=len(vimeo_video_df)):\n",
    "    video_titles.append(name_to_doc(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matches for all video titles\n",
    "matches = [phrase_matcher(vt) for vt in video_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccdf3c5e71f44b38e0b2a25ffa2645e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3019.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_codes = []\n",
    "multi_codes = []\n",
    "\n",
    "for ind, match in tqdm(enumerate(matches), total=len(matches)):\n",
    "    if len(match) == 1:\n",
    "        match_id = match[0][0]\n",
    "        proj_code = nlp.vocab.strings[match_id]\n",
    "        best_codes.append(proj_code)\n",
    "    elif len(match) > 1:\n",
    "        match_ids = [m[0] for m in match]\n",
    "        codes = [nlp.vocab.strings[match_id] for match_id in match_ids]\n",
    "        if codes[0] == 'GEN':\n",
    "            best_codes.append(codes[1])\n",
    "        else:\n",
    "            best_codes.append(None)\n",
    "        multi_codes.append((ind, [nlp.vocab.strings[match_id] for match_id in match_ids]))\n",
    "    else:\n",
    "        best_codes.append(None)\n",
    "    \n",
    "codes = pd.Series(codes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1975d8a2a55a4c58a810a1e68ffe4c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3019.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compare_rows = []\n",
    "for ind, estimated_codes in tqdm(enumerate(best_codes), total=len(best_codes)):\n",
    "    actual_code = vimeo_video_df['Project ID'].iloc[ind]\n",
    "    title = vimeo_video_df['name'].iloc[ind]\n",
    "    row = {'estimated_code':estimated_codes,\n",
    "           'actual_code': actual_code,\n",
    "           'matched': estimated_codes == actual_code,\n",
    "           'title': title}\n",
    "    compare_rows.append(row)\n",
    "compare_df = pd.DataFrame(compare_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792315336204041"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df['matched'].sum() / len(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_estimate_df = compare_df[compare_df['matched'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_estimate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated_code</th>\n",
       "      <th>actual_code</th>\n",
       "      <th>matched</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>GEN</td>\n",
       "      <td>False</td>\n",
       "      <td>OTV Super Trailer - Cycle 4 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>GEN</td>\n",
       "      <td>False</td>\n",
       "      <td>OTV Post-Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>GE</td>\n",
       "      <td>GEN</td>\n",
       "      <td>False</td>\n",
       "      <td>GOOD ENOUGH SEASON ONE _OFFICIAL TRAILER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>GEN</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Open TV Re-Presents: Kissing Walls -- Pilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>None</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Kissing Walls S02 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>None</td>\n",
       "      <td>DG</td>\n",
       "      <td>False</td>\n",
       "      <td>Damaged Goods - Episode 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>None</td>\n",
       "      <td>NOCV</td>\n",
       "      <td>False</td>\n",
       "      <td>#NupitaObama Creates Vogua Premiere: Wicker Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>None</td>\n",
       "      <td>DG</td>\n",
       "      <td>False</td>\n",
       "      <td>Damaged Goods - Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>None</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Kissing Walls S02 EP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>None</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Kissing Walls S02 EP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>None</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Kissing Walls S02 EP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>None</td>\n",
       "      <td>TQIK</td>\n",
       "      <td>False</td>\n",
       "      <td>#2QIK: Elijah McKinnon &amp; AJ Christian (Part One)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>None</td>\n",
       "      <td>KW</td>\n",
       "      <td>False</td>\n",
       "      <td>Kissing Walls S02 EP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>None</td>\n",
       "      <td>NOCV</td>\n",
       "      <td>False</td>\n",
       "      <td>#NupitaObama Creates Vogua Premiere: Lakeview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    estimated_code actual_code  matched  \\\n",
       "12            None         GEN    False   \n",
       "45            None         GEN    False   \n",
       "57              GE         GEN    False   \n",
       "62             GEN          KW    False   \n",
       "63            None          KW    False   \n",
       "67            None          DG    False   \n",
       "79            None        NOCV    False   \n",
       "81            None          DG    False   \n",
       "82            None          KW    False   \n",
       "85            None          KW    False   \n",
       "93            None          KW    False   \n",
       "98            None        TQIK    False   \n",
       "105           None          KW    False   \n",
       "119           None        NOCV    False   \n",
       "\n",
       "                                                title  \n",
       "12                   OTV Super Trailer - Cycle 4 2019  \n",
       "45                                      OTV Post-Roll  \n",
       "57           GOOD ENOUGH SEASON ONE _OFFICIAL TRAILER  \n",
       "62        Open TV Re-Presents: Kissing Walls -- Pilot  \n",
       "63                              Kissing Walls S02 EP1  \n",
       "67                          Damaged Goods - Episode 1  \n",
       "79   #NupitaObama Creates Vogua Premiere: Wicker Park  \n",
       "81                          Damaged Goods - Episode 2  \n",
       "82                              Kissing Walls S02 EP6  \n",
       "85                              Kissing Walls S02 EP4  \n",
       "93                              Kissing Walls S02 EP2  \n",
       "98   #2QIK: Elijah McKinnon & AJ Christian (Part One)  \n",
       "105                             Kissing Walls S02 EP3  \n",
       "119     #NupitaObama Creates Vogua Premiere: Lakeview  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_estimate_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
